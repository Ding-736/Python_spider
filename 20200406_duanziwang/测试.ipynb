{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={\n",
    "    \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://duanziwang.com/category/%E7%BB%8F%E5%85%B8%E6%AE%B5%E5%AD%90/1/\"\n",
    "response=requests.get(url,headers=headers)\n",
    "response.encoding=\"utf-8\"\n",
    "html=response.text\n",
    "root=etree.HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['共 806 页']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern=re.compile(r'共 \\d+ 页')\n",
    "result=pattern.findall(html)\n",
    "int(result[0].split(\" \")[1])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "806"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(result[0].split(\" \")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=root.xpath('//div[@class=\"post-head\"]/h1/a/text()')\n",
    "title=[i.split(\"_\")[0] for i in title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['尼玛虚荣心啊。。',\n",
       " '它的意思是：泥马，去屎',\n",
       " '战俘',\n",
       " '老乞丐和小乞丐',\n",
       " '古诗一首',\n",
       " '收获不小',\n",
       " '欣赏新疆歌舞',\n",
       " '缩写',\n",
       " '怎么选择',\n",
       " '惊喜']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['年轻人。你真的以为有那么多人回复你吗 ？其实我是看你可怜，于是，我不辞辛劳 的注册了很多ID，不断的回复你，希望能 满足一下你的虚荣心。但是你要明白，不 是所有人都会像我这样为你着想。希望你 好自为之。好了，不说了。我换号继续回 复你，不然你不会相信这是真的',\n",
       " '八戒：“猴哥，白龙马最近性情有些古怪，每次我和它开玩笑，它都会在泥地打个滚，然后跑开几步拉马粪。”悟空：“呆子，小白龙不会说话，它的意思是：泥马，去屎……”',\n",
       " '一次战争期间俘获了一个战俘，一年后他得了一种病，左手烂掉了，他请求敌人把他的左手送回他的祖国。敌人很感动，就照做了；不久他的右手也烂掉了，他也请求将右手送回祖国。再后来他的左腿也被截肢，这一次，当他要求把腿送回祖国时，却遭到了拒绝。他很不明白，问敌人为什么前两次可以而这次不行。敌人很郑重地说：“我们怀疑你在有计划地分期分批地逃跑。”',\n",
       " '一个非常冷的冬天，早上一老一小两个乞丐去乞讨，他们走到一家餐厅门口等老板扔剩饭。          功夫不负有心人，不一会老板就拿一桶剩饭出来了，小乞丐连忙上去吃，而老乞丐却站在旁边不动。         因为天气很冷，饭很凉，小乞丐吃了几口就胃难受，所以就吐出来！这时，老乞丐冲了上去，很感动的说：“就等你这口热的了。”',\n",
       " '人生自古谁无屎，有谁大便不用纸？若君不用卫生纸，莫非你是用手指？？？？',\n",
       " '一保洁员在为女生宿舍要打扫卫生，忙了一天的他终于回到家了，看见老婆他忙高兴的说：“今天打扫卫生床下的收获真是不少，既有凉菜，又有水果，还有上锅的！ ”妻子不解的问：“都有什么呀？瞧你乐的！ ”听好了：“有凉拌的黄瓜，生吃的香蕉，还有上锅的茄子！ ”',\n",
       " '一次文艺晚会，主持人上台报幕：下面请欣赏：新疆歌舞，掀起你的头盖骨！全场鸦雀无声！！！',\n",
       " '去上厕所时，看到厕所门上只标一NC的缩写，同去的英语达人曰：NC就是男厕嘛。于是豁然开朗，进，脱，蹲，一气呵成，忽灵光一闪，女厕的缩写是什么来着……',\n",
       " '准备吃午饭了，好丰盛啊！红烧牛肉、海鲜、大虾、泡椒凤爪、葱香排骨、黑胡椒牛排……这么多口味的方便面，该吃哪种呢？',\n",
       " '一个寒冷的清晨，女孩迎来了自己的生日。忽然男友打电话来说：“快看窗外！ ”女孩打开窗，只见楼下白茫茫的雪地上写着几个热气腾腾的大字：生日快乐，我爱.....“是你写的吗？”女孩感动极了。“是啊，可惜尿不够了......”']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content=root.xpath('//div[@class=\"post-content\"]/p/text()')\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['418', '360', '286', '308', '290', '206', '195', '194', '201', '188']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot=root.xpath('//div[@class=\"post-meta\"]/time[2]/text()')\n",
    "hot=[i.replace(\"°C\",\"\") for i in hot]\n",
    "hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9', '6', '3', '6', '11', '2', '2', '5', '3', '1']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhan=root.xpath('//div[@class=\"post-meta\"]/time[3]/a/span/text()')\n",
    "zhan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-02-10',\n",
       " '2020-02-10',\n",
       " '2020-02-10',\n",
       " '2020-02-10',\n",
       " '2020-02-10',\n",
       " '2020-02-10',\n",
       " '2020-02-10',\n",
       " '2020-02-10',\n",
       " '2020-02-10',\n",
       " '2020-02-10']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_time=root.xpath('//div[@class=\"post-meta\"]/time[1]/text()')\n",
    "release_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['title']=title\n",
    "df['content']=content\n",
    "df['hot']=hot\n",
    "df['zhan']=zhan\n",
    "df['date']=release_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"duanzi.csv\", mode=\"a+\", header=None, index=None, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"duanzi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>hot</th>\n",
       "      <th>zhan</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>它的意思是：泥马，去屎</td>\n",
       "      <td>八戒：“猴哥，白龙马最近性情有些古怪，每次我和它开玩笑，它都会在泥地打个滚，然后跑开几步拉马...</td>\n",
       "      <td>360</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>战俘</td>\n",
       "      <td>一次战争期间俘获了一个战俘，一年后他得了一种病，左手烂掉了，他请求敌人把他的左手送回他的祖国...</td>\n",
       "      <td>286</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>老乞丐和小乞丐</td>\n",
       "      <td>一个非常冷的冬天，早上一老一小两个乞丐去乞讨，他们走到一家餐厅门口等老板扔剩饭。      ...</td>\n",
       "      <td>308</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>古诗一首</td>\n",
       "      <td>人生自古谁无屎，有谁大便不用纸？若君不用卫生纸，莫非你是用手指？？？？</td>\n",
       "      <td>290</td>\n",
       "      <td>11</td>\n",
       "      <td>2020-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>收获不小</td>\n",
       "      <td>一保洁员在为女生宿舍要打扫卫生，忙了一天的他终于回到家了，看见老婆他忙高兴的说：“今天打扫卫...</td>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>欣赏新疆歌舞</td>\n",
       "      <td>一次文艺晚会，主持人上台报幕：下面请欣赏：新疆歌舞，掀起你的头盖骨！全场鸦雀无声！！！</td>\n",
       "      <td>195</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>缩写</td>\n",
       "      <td>去上厕所时，看到厕所门上只标一NC的缩写，同去的英语达人曰：NC就是男厕嘛。于是豁然开朗，进...</td>\n",
       "      <td>194</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>怎么选择</td>\n",
       "      <td>准备吃午饭了，好丰盛啊！红烧牛肉、海鲜、大虾、泡椒凤爪、葱香排骨、黑胡椒牛排……这么多口味的...</td>\n",
       "      <td>201</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>惊喜</td>\n",
       "      <td>一个寒冷的清晨，女孩迎来了自己的生日。忽然男友打电话来说：“快看窗外！ ”女孩打开窗，只见楼...</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                            content  hot  zhan  \\\n",
       "0  它的意思是：泥马，去屎  八戒：“猴哥，白龙马最近性情有些古怪，每次我和它开玩笑，它都会在泥地打个滚，然后跑开几步拉马...  360     6   \n",
       "1           战俘  一次战争期间俘获了一个战俘，一年后他得了一种病，左手烂掉了，他请求敌人把他的左手送回他的祖国...  286     3   \n",
       "2      老乞丐和小乞丐  一个非常冷的冬天，早上一老一小两个乞丐去乞讨，他们走到一家餐厅门口等老板扔剩饭。      ...  308     6   \n",
       "3         古诗一首                人生自古谁无屎，有谁大便不用纸？若君不用卫生纸，莫非你是用手指？？？？  290    11   \n",
       "4         收获不小  一保洁员在为女生宿舍要打扫卫生，忙了一天的他终于回到家了，看见老婆他忙高兴的说：“今天打扫卫...  206     2   \n",
       "5       欣赏新疆歌舞        一次文艺晚会，主持人上台报幕：下面请欣赏：新疆歌舞，掀起你的头盖骨！全场鸦雀无声！！！  195     2   \n",
       "6           缩写  去上厕所时，看到厕所门上只标一NC的缩写，同去的英语达人曰：NC就是男厕嘛。于是豁然开朗，进...  194     5   \n",
       "7         怎么选择  准备吃午饭了，好丰盛啊！红烧牛肉、海鲜、大虾、泡椒凤爪、葱香排骨、黑胡椒牛排……这么多口味的...  201     3   \n",
       "8           惊喜  一个寒冷的清晨，女孩迎来了自己的生日。忽然男友打电话来说：“快看窗外！ ”女孩打开窗，只见楼...  188     1   \n",
       "\n",
       "         date  \n",
       "0  2020-02-10  \n",
       "1  2020-02-10  \n",
       "2  2020-02-10  \n",
       "3  2020-02-10  \n",
       "4  2020-02-10  \n",
       "5  2020-02-10  \n",
       "6  2020-02-10  \n",
       "7  2020-02-10  \n",
       "8  2020-02-10  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns=[\"title\",\"content\",\"hot\",\"zhan\",\"date\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一.单线程实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在解析第1页\n",
      "正在解析第2页\n",
      "正在解析第3页\n",
      "正在解析第4页\n",
      "正在解析第5页\n",
      "正在解析第6页\n",
      "正在解析第7页\n",
      "正在解析第8页\n",
      "正在解析第9页\n",
      "正在解析第10页\n",
      "正在解析第11页\n",
      "正在解析第12页\n",
      "正在解析第13页\n",
      "正在解析第14页\n",
      "正在解析第15页\n",
      "正在解析第16页\n",
      "正在解析第17页\n",
      "正在解析第18页\n",
      "正在解析第19页\n",
      "解析完毕!\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "headers={\n",
    "    \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\"\n",
    "}\n",
    "\n",
    "base_url=\"https://duanziwang.com/category/%E7%BB%8F%E5%85%B8%E6%AE%B5%E5%AD%90/{}/\"\n",
    "\n",
    "local_file=open(\"duanzi1.json\",\"a\",encoding=\"utf-8\")\n",
    "\n",
    "def parse_html(html):\n",
    "    \n",
    "    root=etree.HTML(html)\n",
    "    \n",
    "    # 1.标题\n",
    "    title=root.xpath('//div[@class=\"post-head\"]/h1/a/text()')\n",
    "    title=[i.split(\"_\")[0] for i in title]\n",
    "    \n",
    "    # 2.内容\n",
    "    content=root.xpath('//div[@class=\"post-content\"]/p/text()')\n",
    "    \n",
    "    # 3.热度\n",
    "    hot=root.xpath('//div[@class=\"post-meta\"]/time[2]/text()')\n",
    "    hot=[i.replace(\"°C\",\"\") for i in hot]\n",
    "    \n",
    "    # 4.赞\n",
    "    zan=root.xpath('//div[@class=\"post-meta\"]/time[3]/a/span/text()')\n",
    "    \n",
    "    # 5.发布时间\n",
    "    release_time=root.xpath('//div[@class=\"post-meta\"]/time[1]/text()')\n",
    "    \n",
    "    for i in range(len(title)):\n",
    "        try:\n",
    "            items={}\n",
    "            items[\"title\"]=title[i]\n",
    "            items[\"content\"]=content[i]\n",
    "            items[\"hot\"]=hot[i]\n",
    "            items[\"zan\"]=zan[i]\n",
    "            items[\"date\"]=release_time[i]\n",
    "            \n",
    "            \n",
    "            local_file.write(json.dumps(items,ensure_ascii=False)+\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    df=pd.DataFrame()\n",
    "    df['title']=title\n",
    "    df['content']=content\n",
    "    df['hot']=hot\n",
    "    df['zhan']=zan\n",
    "    df['date']=release_time\n",
    "    \n",
    "    try:\n",
    "        df.to_csv(\"duanzi1.csv\", mode=\"a+\", header=None, index=None, encoding=\"utf-8\")\n",
    "    except:\n",
    "        pass\n",
    "          \n",
    "        \n",
    "def main():\n",
    "    \n",
    "    start_url=base_url.format(1)\n",
    "    response=requests.get(start_url,headers=headers)\n",
    "    response.encoding=\"utf-8\"\n",
    "    html=response.text\n",
    "    \n",
    "    pattern=re.compile(r'共 \\d+ 页')\n",
    "    result=pattern.findall(html)\n",
    "    pages=int(result[0].split(\" \")[1])\n",
    "    \n",
    "    for i in range(1,pages+1):\n",
    "        if i==20: break\n",
    "        \n",
    "        print(\"正在解析第{}页\".format(i))\n",
    "        \n",
    "        url=base_url.format(i)\n",
    "        \n",
    "        response=requests.get(url,headers=headers)\n",
    "        response.encoding=\"utf-8\"\n",
    "        html=response.text\n",
    "        \n",
    "        parse_html(html)\n",
    "        \n",
    "        time.sleep(random.randint(2,5))\n",
    "        \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    main()\n",
    "    \n",
    "    local_file.close()\n",
    "    \n",
    "    print(\"解析完毕!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.多线程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import threading\n",
    "from lxml import etree\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from queue import Queue\n",
    "\n",
    "\n",
    "# 采集网页页码队列是否为空的信号\n",
    "CRAWL_EXIT=False\n",
    "\n",
    "class ThreadCrawl(threading.Thread):\n",
    "    \n",
    "    def __init__(self,threadName,pageQueue,dataQueue):\n",
    "        threading.Thread.__init__(self)\n",
    "        \n",
    "        # 线程名\n",
    "        self.threadName=threadName\n",
    "        \n",
    "        # 页码队列\n",
    "        self.pageQueue=pageQueue\n",
    "        \n",
    "        # 数据队列\n",
    "        self.dataQueue=dataQueue\n",
    "        \n",
    "        self.base_url=\"https://duanziwang.com/category/%E7%BB%8F%E5%85%B8%E6%AE%B5%E5%AD%90/{}/\"\n",
    "        \n",
    "        self.headers={\n",
    "            \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\"\n",
    "        }\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        print(\"启动：\"+self.threadName)\n",
    "        \n",
    "        while not CRAWL_EXIT:\n",
    "            \n",
    "            try:\n",
    "                # 从 pageQueue 中取出一个页码数字，先进先出\n",
    "                # 可选参数block 默认值为True\n",
    "                # 如果队列为空 block为True 会进入阻塞状态 直到队列有新的数据\n",
    "                # 如果队列为空 block为False 会返回一个Queue.empty()异常\n",
    "                \n",
    "                page=self.pageQueue.get(False)\n",
    "                \n",
    "                url=self.base_url.format(page)\n",
    "                \n",
    "                response=requests.get(url,headers=self.headers)\n",
    "                response.encoding=\"utf-8\"\n",
    "                html=response.text\n",
    "                \n",
    "                self.dataQueue.put(html)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "        print(\"结束：\"+self.threadName)\n",
    "        \n",
    "        \n",
    "\n",
    "# 网页源代码队列是否为空的信号\n",
    "PARSE_EXIT=False\n",
    "\n",
    "class ThreadParse(threading.Thread):\n",
    "    \n",
    "    def __init__(self,threadName,dataQueue,localFile,lock):\n",
    "        \n",
    "        super(ThreadParse,self).__init__()\n",
    "        \n",
    "        # 线程名\n",
    "        self.threadName=threadName\n",
    "        \n",
    "        # 数据队列\n",
    "        self.dataQueue=dataQueue\n",
    "        \n",
    "        # 保存解析后数据的文件名\n",
    "        self.localFile=localFile\n",
    "        \n",
    "        # 互斥锁\n",
    "        self.lock=lock\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        print(\"启动：\"+self.threadName)\n",
    "        \n",
    "        while not PARSE_EXIT:\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                html=self.dataQueue.get(False)\n",
    "                self.parse2(html)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "        print(\"结束：\"+self.threadName)\n",
    "        \n",
    "    def parse1(self,html):\n",
    "        \n",
    "        root=etree.HTML(html)\n",
    "        \n",
    "        # 1.标题\n",
    "        title=root.xpath('//div[@class=\"post-head\"]/h1/a/text()')\n",
    "        title=[i.split(\"_\")[0] for i in title]\n",
    "    \n",
    "        # 2.内容\n",
    "        content=root.xpath('//div[@class=\"post-content\"]/p/text()')\n",
    "    \n",
    "        # 3.热度\n",
    "        hot=root.xpath('//div[@class=\"post-meta\"]/time[2]/text()')\n",
    "        hot=[i.replace(\"°C\",\"\") for i in hot]\n",
    "    \n",
    "        # 4.赞\n",
    "        zan=root.xpath('//div[@class=\"post-meta\"]/time[3]/a/span/text()')\n",
    "    \n",
    "        # 5.发布时间\n",
    "        release_time=root.xpath('//div[@class=\"post-meta\"]/time[1]/text()')\n",
    "\n",
    "        for i in range(len(title)):\n",
    "            try:\n",
    "                items={}\n",
    "                items[\"title\"]=title[i]\n",
    "                items[\"content\"]=content[i]\n",
    "                items[\"hot\"]=hot[i]\n",
    "                items[\"zan\"]=zan[i]\n",
    "                items[\"date\"]=release_time[i]\n",
    "\n",
    "                with self.lock:\n",
    "                    self.localFile.write(json.dumps(items,ensure_ascii=False)+\"\\n\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "    def parse2(self,html):\n",
    "        \n",
    "        root=etree.HTML(html)\n",
    "        \n",
    "        # 1.标题\n",
    "        title=root.xpath('//div[@class=\"post-head\"]/h1/a/text()')\n",
    "        title=[i.split(\"_\")[0] for i in title]\n",
    "    \n",
    "        # 2.内容\n",
    "        content=root.xpath('//div[@class=\"post-content\"]/p/text()')\n",
    "    \n",
    "        # 3.热度\n",
    "        hot=root.xpath('//div[@class=\"post-meta\"]/time[2]/text()')\n",
    "        hot=[i.replace(\"°C\",\"\") for i in hot]\n",
    "    \n",
    "        # 4.赞\n",
    "        zan=root.xpath('//div[@class=\"post-meta\"]/time[3]/a/span/text()')\n",
    "    \n",
    "        # 5.发布时间\n",
    "        release_time=root.xpath('//div[@class=\"post-meta\"]/time[1]/text()')\n",
    "\n",
    "        df=pd.DataFrame()\n",
    "        df['title']=title\n",
    "        df['content']=content\n",
    "        df['hot']=hot\n",
    "        df['zhan']=zan\n",
    "        df['date']=release_time\n",
    "\n",
    "        try:\n",
    "            with lock:\n",
    "                df.to_csv(\"duanzi2_2.csv\", mode=\"a+\", header=None, index=None, encoding=\"utf-8\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "def main():\n",
    "    \n",
    "    base_url=\"https://duanziwang.com/category/%E7%BB%8F%E5%85%B8%E6%AE%B5%E5%AD%90/{}/\"\n",
    "    \n",
    "    start_url=base_url.format(1)\n",
    "    response=requests.get(start_url,headers=headers)\n",
    "    response.encoding=\"utf-8\"\n",
    "    html=response.text\n",
    "    \n",
    "    pattern=re.compile(r'共 \\d+ 页')\n",
    "    result=pattern.findall(html)\n",
    "    pages=int(result[0].split(\" \")[1])\n",
    "    \n",
    "    pageQueue=Queue()\n",
    "    \n",
    "    for i in range(1,pages+1):\n",
    "        pageQueue.put(i)\n",
    "        \n",
    "    dataQueue=Queue()\n",
    "    \n",
    "    localFile=open(\"duanzi2_1.json\",\"a\",encoding=\"utf-8\")\n",
    "    \n",
    "    lock=threading.Lock()\n",
    "    \n",
    "    crawlList=[\"采集线程1号\",\"采集线程2号\",\"采集线程3号\"]\n",
    "    \n",
    "    threadCrawls=[]\n",
    "    for threadName in crawlList:\n",
    "        thread=ThreadCrawl(threadName,pageQueue,dataQueue)\n",
    "        thread.start()\n",
    "        threadCrawls.append(thread)\n",
    "        \n",
    "    parseList=[\"解析线程1号\",\"解析线程2号\",\"解析线程3号\"]\n",
    "    \n",
    "    threadParses=[]\n",
    "    for threadName in parseList:\n",
    "        thread=ThreadParse(threadName,dataQueue,localFile,lock)\n",
    "        thread.start()\n",
    "        threadParses.append(thread)\n",
    "        \n",
    "    while not pageQueue.empty():\n",
    "        pass\n",
    "    \n",
    "    global CRAWL_EXIT\n",
    "    CRAWL_EXIT=True\n",
    "    \n",
    "    print(\"pageQueue为空\")\n",
    "    \n",
    "    for thread in threadCrawls:\n",
    "        thread.join()\n",
    "        \n",
    "    while not dataQueue.empty():\n",
    "        pass\n",
    "    \n",
    "    print(\"dataQueue为空\")\n",
    "    \n",
    "    global PARSE_EXIT\n",
    "    PARSE_EXIT=True\n",
    "    \n",
    "    for thread in threadParses:\n",
    "        thread.join()\n",
    "        \n",
    "    with lock:\n",
    "        localFile.close()\n",
    "        \n",
    "        \n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"duanzi1.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "    \n",
    "    row=f.readline()\n",
    "    data=json.loads(row)\n",
    "    print(type(data))\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '尼玛虚荣心啊。。',\n",
       " 'content': '年轻人。你真的以为有那么多人回复你吗 ？其实我是看你可怜，于是，我不辞辛劳 的注册了很多ID，不断的回复你，希望能 满足一下你的虚荣心。但是你要明白，不 是所有人都会像我这样为你着想。希望你 好自为之。好了，不说了。我换号继续回 复你，不然你不会相信这是真的',\n",
       " 'hot': '418',\n",
       " 'zan': '9',\n",
       " 'date': '2020-02-10'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title', 'content', 'hot', 'zan', 'date']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“不称职”',\n",
       " '有一次，小约翰偷偷地对爸爸说：“爸爸，我想对您说句话。”“说吧！ ”爸爸回答。“我认为妈妈不会照料小孩。”“你是怎么知道的呢？”爸爸惊奇地问。“我是亲身体会到的，”约翰说，“我不想睡的时候，妈妈偏要我上床；我睡得正香的时候，她又把我叫醒了。”',\n",
       " '19',\n",
       " '0',\n",
       " '2020-01-30']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('duanzi1.json','r',encoding='utf-8') as f:\n",
    "    \n",
    "    for row in f.readlines():\n",
    "        data=json.loads(row)\n",
    "        datas=list(data.values())\n",
    "        df=pd.DataFrame()\n",
    "        \n",
    "        df['title']=datas[0]\n",
    "        df['content']=datas[1]\n",
    "        df['hot']=datas[2]\n",
    "        df['zan']=datas[3]\n",
    "        df['date']=datas[4]\n",
    "        \n",
    "        try:\n",
    "            df.to_csv(\"test.csv\", mode=\"a+\", header=None, index=None, encoding=\"utf-8\")\n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "datas=[]\n",
    "\n",
    "with open(\"duanzi2_1.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        data=list(json.loads(line).values())\n",
    "        datas.append(data)\n",
    "        \n",
    "with open('duanzi2_2.csv', 'a', encoding='utf-8', newline='') as csvFile:\n",
    "    csv.writer(csvFile).writerow(['title','content','hot','zan','date'])\n",
    "    for rows in datas:\n",
    "        csv.writer(csvFile).writerow(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
